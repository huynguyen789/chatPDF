{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas plotly numpy scipy scikit-learn PyPDF2 termcolor python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support functions\n",
    "## Functions:\n",
    "\n",
    "    prettyPrint(text): Prints the input text in a pretty format with a maximum width of 100 characters per line\n",
    "\n",
    "    get_response(messages): Sends a message to OpenAI's GPT-3 model with the provided messages and returns the response\n",
    "\n",
    "    get_answer(user_query, combined_text): Combines the user's question and the provided text and sends it to OpenAI's GPT-3 model to get a short and precise answer in bullet points, then returns the answer\n",
    "\n",
    "    get_answer_stream(user_query, combined_text): Continuously streams the response from OpenAI's GPT-3 model for the provided user query and text combination in bullet points\n",
    "    \n",
    "## Classes:\n",
    "    \n",
    "    aiSummarizer: A class that initializes an OpenAI API key and a GPT-3 model, preprocesses text by removing unnecessary characters and stop words, and summarizes input text with the GPT-3 model by splitting the input text into chunks and sending each chunk as a message to the GPT-3 model to get a summarized response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from getpass import getpass\n",
    "import sklearn\n",
    "from openai.embeddings_utils import get_embedding\n",
    "from openai.embeddings_utils import cosine_similarity\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "import re\n",
    "from IPython.display import Markdown\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key  = os.getenv('API_KEY')\n",
    "\n",
    "\n",
    "\n",
    "def prettyPrint(text):\n",
    "  # wrap the text to a maximum width of 20 characters\n",
    "  wrapped_lines = textwrap.wrap(text, width=100)\n",
    "\n",
    "  # print each wrapped line\n",
    "  for line in wrapped_lines:\n",
    "      print(line)\n",
    "      \n",
    "      \n",
    "import re\n",
    "import textwrap\n",
    "import openai\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "class aiSummarizer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.openai_api_key = os.getenv('API_KEY')\n",
    "        openai.api_key = self.openai_api_key\n",
    "        self.openai_model = \"gpt-3.5-turbo\"\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.summary = \"\"\n",
    "        \n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        # Remove any citations, parentheses, and brackets\n",
    "        text = re.sub(r\"\\[[^\\]]*\\]\", \"\", text)\n",
    "        text = re.sub(r\"\\([^\\)]*\\)\", \"\", text)\n",
    "        text = re.sub(r\"\\{[^\\}]*\\}\", \"\", text)\n",
    "\n",
    "        # Remove any extra white space\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        # Remove stop words\n",
    "        words = text.split()\n",
    "        words = [word for word in words if word.lower() not in self.stop_words]\n",
    "        text = \" \".join(words)\n",
    "        return text\n",
    "    \n",
    "    def summarize_text(self, text, prompt=\"Summarize, keep it short but capture all the important points of the text below:\", max_length=500):\n",
    "        text_chunks = self.split_text(text, max_length=4000)\n",
    "        summarized_text = \"\"\n",
    "\n",
    "        for i, chunk in enumerate(text_chunks):\n",
    "            print(f\"Summarizing chunk {i+1} of {len(text_chunks)}\")\n",
    "            messages = [\n",
    "              {\"role\": \"system\", \"content\": \"You are a super intelligence AI assistant\"},\n",
    "              {\"role\": \"user\", \"content\": prompt + chunk}\n",
    "            ]\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=self.openai_model,\n",
    "                messages=messages,\n",
    "                temperature=0\n",
    "            )\n",
    "            summarized_text += response['choices'][0]['message']['content'] \n",
    "        print(\"Summarizing process completed\")\n",
    "        return summarized_text\n",
    "    \n",
    "    def split_text(self, text, max_length):\n",
    "        if len(text) <= max_length:\n",
    "            return [text]\n",
    "\n",
    "        chunks = textwrap.wrap(text, max_length)\n",
    "        return chunks\n",
    "\n",
    "# # Initialize the AIAssistant\n",
    "# aiSummarizer = aiSummarizer()\n",
    "\n",
    "\n",
    "# # Summarize the input text\n",
    "# summary = aiSummarizer.summarize_text(text)\n",
    "# print(len(summary))\n",
    "# prettyPrint(summary)\n",
    "\n",
    "#Use the user query and combined text to get the answer:\n",
    "def get_response(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=2000\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def get_answer(user_query, combined_text):\n",
    "    messages = [\n",
    "          {\"role\": \"system\", \"content\": \"You are a super intelligence AI assistant\"},\n",
    "          {\"role\": \"user\", \"content\": f\"Question: {user_query}, context: {combined_text}. \\\n",
    "              Keep the answer short and precise. DO NOT adjust the original question. Show both question and answer in Markdown format, bullet points.\"},\n",
    "        ]\n",
    "    response = get_response(messages)\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "#Use the user query and combined text to get the answer:\n",
    "def get_response(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=2000\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def get_answer(user_query, combined_text):\n",
    "    messages = [\n",
    "          {\"role\": \"user\", \"content\": f\"Question: {user_query}, context: {combined_text}. \\\n",
    "              Keep the answer short and precise. DO NOT adjust the original question. Show both question and answer in Markdown format, bullet points.\"},\n",
    "        ]\n",
    "    response = get_response(messages)\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "def get_answer_stream(user_query, combined_text):\n",
    "    for chunk in openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "          \n",
    "          {\"role\": \"user\", \"content\": f\"\"\" This is a program let the user ask questions about the file.\n",
    "                user question: {user_query}?, file: {combined_text}.\n",
    "                Do not change the question. Keep answer short and precise, cite your source. Show both question and answer in Markdown format, use bullet points in answer\n",
    "                    \"\"\"},\n",
    "        ],\n",
    "        stream=True,\n",
    "    ):\n",
    "        content = chunk[\"choices\"][0].get(\"delta\", {}).get(\"content\")\n",
    "        if content is not None:\n",
    "            print(colored(content, 'white'), end='')\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF to embedding\n",
    "    The pdf_embed_df() function takes a PDF file name as input and returns a dataframe with text chunks and their embeddings.\n",
    "        The function reads the PDF file and extracts its text using PyPDF2.\n",
    "        The extracted text is split into chunks of 500 characters and stored in a dataframe.\n",
    "        The function saves the processed text and embeddings to separate CSV files.\n",
    "        The function uses OpenAI's text-embedding-ada-002 model to generate embeddings for the text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading PDF file: tesla.pdf\n",
      "Saving processed text as CSV file: processed_tesla.csv\n",
      "Embedding text using OpenAI's text-embedding-ada-002 model...\n",
      "Saving text embeddings as CSV file: processed_tesla_embeddings.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q4 and FY 2022 Update\\n1Highlights 03\\nFinanci...</td>\n",
       "      <td>500</td>\n",
       "      <td>[-0.003069573547691107, -0.016441890969872475,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0% in Q4\\n$13.7B GAAP operating income in 20...</td>\n",
       "      <td>500</td>\n",
       "      <td>[-0.022131500765681267, -0.023385969921946526,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that there are questions about the near -\\nte...</td>\n",
       "      <td>500</td>\n",
       "      <td>[-0.03230626508593559, -0.02757885493338108, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many years. \\nImproving affordability is neces...</td>\n",
       "      <td>500</td>\n",
       "      <td>[-0.008768563158810139, 0.0005116421962156892,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g \\nfocused on the long -term potential of aut...</td>\n",
       "      <td>500</td>\n",
       "      <td>[-0.003139789216220379, -0.019092140719294548,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>ing our products and features cost-effectively...</td>\n",
       "      <td>500</td>\n",
       "      <td>[0.00832277536392212, -0.0011817450867965817, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>at Gigafactory Nevada and Gigafactory Shanghai...</td>\n",
       "      <td>500</td>\n",
       "      <td>[0.012574231252074242, -0.026666156947612762, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>to maintain public credibility and confidence ...</td>\n",
       "      <td>500</td>\n",
       "      <td>[0.009611119516193867, -0.02292659506201744, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>s \\nand laws applicable to our operations and ...</td>\n",
       "      <td>500</td>\n",
       "      <td>[-0.006075656041502953, -0.018671853467822075,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>October 24, 2022. Tesla disclaims any obligati...</td>\n",
       "      <td>191</td>\n",
       "      <td>[-0.02474147081375122, -0.022436365485191345, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  length  \\\n",
       "0   Q4 and FY 2022 Update\\n1Highlights 03\\nFinanci...     500   \n",
       "1   6.0% in Q4\\n$13.7B GAAP operating income in 20...     500   \n",
       "2    that there are questions about the near -\\nte...     500   \n",
       "3   many years. \\nImproving affordability is neces...     500   \n",
       "4   g \\nfocused on the long -term potential of aut...     500   \n",
       "..                                                ...     ...   \n",
       "76  ing our products and features cost-effectively...     500   \n",
       "77  at Gigafactory Nevada and Gigafactory Shanghai...     500   \n",
       "78  to maintain public credibility and confidence ...     500   \n",
       "79  s \\nand laws applicable to our operations and ...     500   \n",
       "80  October 24, 2022. Tesla disclaims any obligati...     191   \n",
       "\n",
       "                                            embedding  \n",
       "0   [-0.003069573547691107, -0.016441890969872475,...  \n",
       "1   [-0.022131500765681267, -0.023385969921946526,...  \n",
       "2   [-0.03230626508593559, -0.02757885493338108, 0...  \n",
       "3   [-0.008768563158810139, 0.0005116421962156892,...  \n",
       "4   [-0.003139789216220379, -0.019092140719294548,...  \n",
       "..                                                ...  \n",
       "76  [0.00832277536392212, -0.0011817450867965817, ...  \n",
       "77  [0.012574231252074242, -0.026666156947612762, ...  \n",
       "78  [0.009611119516193867, -0.02292659506201744, 0...  \n",
       "79  [-0.006075656041502953, -0.018671853467822075,...  \n",
       "80  [-0.02474147081375122, -0.022436365485191345, ...  \n",
       "\n",
       "[81 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def pdf_embed_df():\n",
    "    # Ask the user to input the PDF file name\n",
    "    pdf_file = input(\"Enter the PDF file name: \")\n",
    "\n",
    "    print(f\"Reading PDF file: {pdf_file}\")\n",
    "    # Read the PDF file using PyPDF2\n",
    "    inputpdf = PdfReader(open(pdf_file, \"rb\"))\n",
    "\n",
    "    pdf_text = ''  # Initialize an empty string to store the PDF text\n",
    "    # Loop over each page of the PDF file\n",
    "    for i in range(len(inputpdf.pages)):\n",
    "        text = inputpdf.pages[i].extract_text()  # Extract the text from the current page\n",
    "        pdf_text += text  # Append the cleaned text to the `pdf_text` string\n",
    "    # print(f\"PDF text extracted successfully: {pdf_text}\")\n",
    "    \n",
    "    # Split the text into chunks of 500 characters\n",
    "    chunks = [pdf_text[i:i+500] for i in range(0, len(pdf_text), 500)]\n",
    "\n",
    "    # Create a dataframe with the chunks\n",
    "    df = pd.DataFrame(chunks, columns=['text'])\n",
    "\n",
    "    # Remove the \".pdf\" extension from the original file name\n",
    "    file_name = pdf_file.split(\".\")[0]\n",
    "    \n",
    "    # Add a new column 'length' to the DataFrame\n",
    "    df['length'] = df['text'].str.len()\n",
    "\n",
    "    # Save the DataFrame to a CSV file with \"processed_\" prepended to the original file name\n",
    "    processed_filename = f\"processed_{file_name}.csv\"\n",
    "    print(f\"Saving processed text as CSV file: {processed_filename}\")\n",
    "    df.to_csv(processed_filename, index=False)\n",
    "\n",
    "    # Embed the text using OpenAI's text-embedding-ada-002 model\n",
    "    print(\"Embedding text using OpenAI's text-embedding-ada-002 model...\")\n",
    "    df['embedding'] = df['text'].apply(lambda x: get_embedding(x, engine='text-embedding-ada-002'))\n",
    "\n",
    "    # Save the DataFrame to a CSV file with \"processed_\" prepended to the original file name\n",
    "    embeddings_filename = f\"processed_{file_name}_embeddings.csv\"\n",
    "    print(f\"Saving text embeddings as CSV file: {embeddings_filename}\")\n",
    "    df.to_csv(embeddings_filename, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = pdf_embed_df()\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run program\n",
    "    Prompt user for a search query\n",
    "    Embed the query using OpenAI's text-embedding-ada-002 model\n",
    "    Calculate cosine similarity between the query vector and each text block in the preprocessed PDF\n",
    "    Sort the blocks by similarity and combine the top 5 most similar blocks\n",
    "    If the length of the combined text is greater than 3500, summarize it using OpenAI's GPT-3.5 model\n",
    "    Print the answer to the user in a stream format using Markdown format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>embedding</th>\n",
       "      <th>similarities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8 621 599 \\nTotal automotive revenue 15,967 16...</td>\n",
       "      <td>500</td>\n",
       "      <td>[0.004110813606530428, -0.022544672712683678, ...</td>\n",
       "      <td>0.807902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1,579 1,605 \\nTotal cost of revenues 12,872 13...</td>\n",
       "      <td>500</td>\n",
       "      <td>[-0.018536904826760292, -0.009518403559923172,...</td>\n",
       "      <td>0.796155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tion and impairment 1,901 2,154 2,322 2,911 3,...</td>\n",
       "      <td>500</td>\n",
       "      <td>[-0.016233323141932487, -0.003794889198616147,...</td>\n",
       "      <td>0.767976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2,101) (1,327) (3,157) (6,482) (7,158) 10%\\nFr...</td>\n",
       "      <td>500</td>\n",
       "      <td>[-0.007092054933309555, -0.02074492536485195, ...</td>\n",
       "      <td>0.761009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0% in Q4\\n$13.7B GAAP operating income in 20...</td>\n",
       "      <td>500</td>\n",
       "      <td>[-0.022131500765681267, -0.023385969921946526,...</td>\n",
       "      <td>0.760369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>at Gigafactory Nevada and Gigafactory Shanghai...</td>\n",
       "      <td>500</td>\n",
       "      <td>[0.012574231252074242, -0.026666156947612762, ...</td>\n",
       "      <td>0.681176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>house 4680 cells in a single \\nweek to make ov...</td>\n",
       "      <td>500</td>\n",
       "      <td>[0.007835561409592628, -0.026911381632089615, ...</td>\n",
       "      <td>0.679665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>and Full Self -Driving (FSD)\\nWe have now rel...</td>\n",
       "      <td>500</td>\n",
       "      <td>[0.015706012025475502, -0.017201192677021027, ...</td>\n",
       "      <td>0.672717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>es. These forward -looking statements are base...</td>\n",
       "      <td>500</td>\n",
       "      <td>[-0.0066046989522874355, -0.02313307486474514,...</td>\n",
       "      <td>0.671296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>October 24, 2022. Tesla disclaims any obligati...</td>\n",
       "      <td>191</td>\n",
       "      <td>[-0.02474147081375122, -0.022436365485191345, ...</td>\n",
       "      <td>0.666065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  length  \\\n",
       "41  8 621 599 \\nTotal automotive revenue 15,967 16...     500   \n",
       "42  1,579 1,605 \\nTotal cost of revenues 12,872 13...     500   \n",
       "59  tion and impairment 1,901 2,154 2,322 2,911 3,...     500   \n",
       "11  2,101) (1,327) (3,157) (6,482) (7,158) 10%\\nFr...     500   \n",
       "1   6.0% in Q4\\n$13.7B GAAP operating income in 20...     500   \n",
       "..                                                ...     ...   \n",
       "77  at Gigafactory Nevada and Gigafactory Shanghai...     500   \n",
       "23  house 4680 cells in a single \\nweek to make ov...     500   \n",
       "25   and Full Self -Driving (FSD)\\nWe have now rel...     500   \n",
       "75  es. These forward -looking statements are base...     500   \n",
       "80  October 24, 2022. Tesla disclaims any obligati...     191   \n",
       "\n",
       "                                            embedding  similarities  \n",
       "41  [0.004110813606530428, -0.022544672712683678, ...      0.807902  \n",
       "42  [-0.018536904826760292, -0.009518403559923172,...      0.796155  \n",
       "59  [-0.016233323141932487, -0.003794889198616147,...      0.767976  \n",
       "11  [-0.007092054933309555, -0.02074492536485195, ...      0.761009  \n",
       "1   [-0.022131500765681267, -0.023385969921946526,...      0.760369  \n",
       "..                                                ...           ...  \n",
       "77  [0.012574231252074242, -0.026666156947612762, ...      0.681176  \n",
       "23  [0.007835561409592628, -0.026911381632089615, ...      0.679665  \n",
       "25  [0.015706012025475502, -0.017201192677021027, ...      0.672717  \n",
       "75  [-0.0066046989522874355, -0.02313307486474514,...      0.671296  \n",
       "80  [-0.02474147081375122, -0.022436365485191345, ...      0.666065  \n",
       "\n",
       "[81 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m**\u001b[0m\u001b[32mUser\u001b[0m\u001b[32m Question\u001b[0m\u001b[32m:**\u001b[0m\u001b[32m What\u001b[0m\u001b[32m is\u001b[0m\u001b[32m Tesla\u001b[0m\u001b[32m's\u001b[0m\u001b[32m current\u001b[0m\u001b[32m capacity\u001b[0m\u001b[32m?\n",
      "\n",
      "\u001b[0m\u001b[32m**\u001b[0m\u001b[32mAnswer\u001b[0m\u001b[32m:\u001b[0m\u001b[32m**\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m California\u001b[0m\u001b[32m Model\u001b[0m\u001b[32m S\u001b[0m\u001b[32m /\u001b[0m\u001b[32m Model\u001b[0m\u001b[32m X\u001b[0m\u001b[32m:\u001b[0m\u001b[32m \u001b[0m\u001b[32m100\u001b[0m\u001b[32m,\u001b[0m\u001b[32m000\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m California\u001b[0m\u001b[32m Model\u001b[0m\u001b[32m \u001b[0m\u001b[32m3\u001b[0m\u001b[32m /\u001b[0m\u001b[32m Model\u001b[0m\u001b[32m Y\u001b[0m\u001b[32m:\u001b[0m\u001b[32m \u001b[0m\u001b[32m550\u001b[0m\u001b[32m,\u001b[0m\u001b[32m000\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m Shanghai\u001b[0m\u001b[32m Model\u001b[0m\u001b[32m \u001b[0m\u001b[32m3\u001b[0m\u001b[32m /\u001b[0m\u001b[32m Model\u001b[0m\u001b[32m Y\u001b[0m\u001b[32m:\u001b[0m\u001b[32m >\u001b[0m\u001b[32m750\u001b[0m\u001b[32m,\u001b[0m\u001b[32m000\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m Berlin\u001b[0m\u001b[32m Model\u001b[0m\u001b[32m Y\u001b[0m\u001b[32m:\u001b[0m\u001b[32m >\u001b[0m\u001b[32m250\u001b[0m\u001b[32m,\u001b[0m\u001b[32m000\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m Texas\u001b[0m\u001b[32m Model\u001b[0m\u001b[32m Y\u001b[0m\u001b[32m:\u001b[0m\u001b[32m >\u001b[0m\u001b[32m250\u001b[0m\u001b[32m,\u001b[0m\u001b[32m000\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m Cyber\u001b[0m\u001b[32mtruck\u001b[0m\u001b[32m,\u001b[0m\u001b[32m Tesla\u001b[0m\u001b[32m Semi\u001b[0m\u001b[32m,\u001b[0m\u001b[32m Road\u001b[0m\u001b[32mster\u001b[0m\u001b[32m,\u001b[0m\u001b[32m Robot\u001b[0m\u001b[32max\u001b[0m\u001b[32mi\u001b[0m\u001b[32m &\u001b[0m\u001b[32m Others\u001b[0m\u001b[32m:\u001b[0m\u001b[32m In\u001b[0m\u001b[32m development\u001b[0m\u001b[32m\n",
      "\n",
      "\u001b[0m\u001b[32m*(\u001b[0m\u001b[32mSource\u001b[0m\u001b[32m:\u001b[0m\u001b[32m File\u001b[0m\u001b[32m:\u001b[0m\u001b[32m Installed\u001b[0m\u001b[32m Annual\u001b[0m\u001b[32m Vehicle\u001b[0m\u001b[32m Capacity\u001b[0m\u001b[32m)*\u001b[0m\n",
      "\n",
      "\u001b[32mUser\u001b[0m\u001b[32m question\u001b[0m\u001b[32m:\u001b[0m\u001b[32m Financial\u001b[0m\u001b[32m summary\u001b[0m\u001b[32m?\n",
      "\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m Total\u001b[0m\u001b[32m revenue\u001b[0m\u001b[32m in\u001b[0m\u001b[32m Q\u001b[0m\u001b[32m4\u001b[0m\u001b[32m:\u001b[0m\u001b[32m $\u001b[0m\u001b[32m24\u001b[0m\u001b[32m.\u001b[0m\u001b[32m3\u001b[0m\u001b[32m billion\u001b[0m\u001b[32m (\u001b[0m\u001b[32m37\u001b[0m\u001b[32m%\u001b[0m\u001b[32m Yo\u001b[0m\u001b[32mY\u001b[0m\u001b[32m growth\u001b[0m\u001b[32m)\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m Gross\u001b[0m\u001b[32m profit\u001b[0m\u001b[32m in\u001b[0m\u001b[32m Q\u001b[0m\u001b[32m4\u001b[0m\u001b[32m:\u001b[0m\u001b[32m $\u001b[0m\u001b[32m5\u001b[0m\u001b[32m.\u001b[0m\u001b[32m777\u001b[0m\u001b[32m billion\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m Operating\u001b[0m\u001b[32m margin\u001b[0m\u001b[32m in\u001b[0m\u001b[32m \u001b[0m\u001b[32m202\u001b[0m\u001b[32m2\u001b[0m\u001b[32m:\u001b[0m\u001b[32m \u001b[0m\u001b[32m16\u001b[0m\u001b[32m.\u001b[0m\u001b[32m8\u001b[0m\u001b[32m%\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m Free\u001b[0m\u001b[32m cash\u001b[0m\u001b[32m flow\u001b[0m\u001b[32m in\u001b[0m\u001b[32m \u001b[0m\u001b[32m202\u001b[0m\u001b[32m2\u001b[0m\u001b[32m:\u001b[0m\u001b[32m $\u001b[0m\u001b[32m7\u001b[0m\u001b[32m.\u001b[0m\u001b[32m566\u001b[0m\u001b[32m billion\u001b[0m\u001b[32m (\u001b[0m\u001b[32m51\u001b[0m\u001b[32m%\u001b[0m\u001b[32m growth\u001b[0m\u001b[32m)\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m Cash\u001b[0m\u001b[32m,\u001b[0m\u001b[32m cash\u001b[0m\u001b[32m equivalents\u001b[0m\u001b[32m,\u001b[0m\u001b[32m and\u001b[0m\u001b[32m investments\u001b[0m\u001b[32m in\u001b[0m\u001b[32m \u001b[0m\u001b[32m202\u001b[0m\u001b[32m2\u001b[0m\u001b[32m:\u001b[0m\u001b[32m $\u001b[0m\u001b[32m22\u001b[0m\u001b[32m.\u001b[0m\u001b[32m185\u001b[0m\u001b[32m billion\u001b[0m\u001b[32m (\u001b[0m\u001b[32m25\u001b[0m\u001b[32m%\u001b[0m\u001b[32m growth\u001b[0m\u001b[32m)\n",
      "\n",
      "\u001b[0m\u001b[32mSource\u001b[0m\u001b[32m:\u001b[0m\u001b[32m Q\u001b[0m\u001b[32m4\u001b[0m\u001b[32m and\u001b[0m\u001b[32m FY\u001b[0m\u001b[32m \u001b[0m\u001b[32m202\u001b[0m\u001b[32m2\u001b[0m\u001b[32m Update\u001b[0m\u001b[32m,\u001b[0m\u001b[32m Pages\u001b[0m\u001b[32m \u001b[0m\u001b[32m4\u001b[0m\u001b[32m-\u001b[0m\u001b[32m5\u001b[0m\n",
      "\n",
      "\u001b[32m**\u001b[0m\u001b[32mUser\u001b[0m\u001b[32m question\u001b[0m\u001b[32m:**\u001b[0m\u001b[32m What\u001b[0m\u001b[32m can\u001b[0m\u001b[32m you\u001b[0m\u001b[32m tell\u001b[0m\u001b[32m me\u001b[0m\u001b[32m about\u001b[0m\u001b[32m F\u001b[0m\u001b[32mSD\u001b[0m\u001b[32m and\u001b[0m\u001b[32m software\u001b[0m\u001b[32m?\n",
      "\n",
      "\u001b[0m\u001b[32m**\u001b[0m\u001b[32mAnswer\u001b[0m\u001b[32m:\u001b[0m\u001b[32m**\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m F\u001b[0m\u001b[32mSD\u001b[0m\u001b[32m stands\u001b[0m\u001b[32m for\u001b[0m\u001b[32m Full\u001b[0m\u001b[32m Self\u001b[0m\u001b[32m-\u001b[0m\u001b[32mDriving\u001b[0m\u001b[32m (\u001b[0m\u001b[32mF\u001b[0m\u001b[32mSD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Beta\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m Released\u001b[0m\u001b[32m to\u001b[0m\u001b[32m nearly\u001b[0m\u001b[32m all\u001b[0m\u001b[32m customers\u001b[0m\u001b[32m in\u001b[0m\u001b[32m the\u001b[0m\u001b[32m US\u001b[0m\u001b[32m and\u001b[0m\u001b[32m Canada\u001b[0m\u001b[32m who\u001b[0m\u001b[32m purchased\u001b[0m\u001b[32m F\u001b[0m\u001b[32mSD\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m Enables\u001b[0m\u001b[32m access\u001b[0m\u001b[32m to\u001b[0m\u001b[32m AI\u001b[0m\u001b[32m-powered\u001b[0m\u001b[32m autonomous\u001b[0m\u001b[32m driving\u001b[0m\u001b[32m functionality\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m Part\u001b[0m\u001b[32m of\u001b[0m\u001b[32m the\u001b[0m\u001b[32m annual\u001b[0m\u001b[32m holiday\u001b[0m\u001b[32m release\u001b[0m\u001b[32m with\u001b[0m\u001b[32m other\u001b[0m\u001b[32m software\u001b[0m\u001b[32m updates\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m Deferred\u001b[0m\u001b[32m revenue\u001b[0m\u001b[32m recognition\u001b[0m\u001b[32m for\u001b[0m\u001b[32m software\u001b[0m\u001b[32m updates\u001b[0m\u001b[32m delivery\u001b[0m\u001b[32m (\u001b[0m\u001b[32mSource\u001b[0m\u001b[32m:\u001b[0m\u001b[32m F\u001b[0m\u001b[32mSD\u001b[0m\u001b[32m release\u001b[0m\u001b[32m details\u001b[0m\u001b[32m in\u001b[0m\u001b[32m the\u001b[0m\u001b[32m given\u001b[0m\u001b[32m text\u001b[0m\u001b[32m)\u001b[0m\n",
      "\n",
      "\u001b[32m**\u001b[0m\u001b[32mUser\u001b[0m\u001b[32m question\u001b[0m\u001b[32m:**\u001b[0m\u001b[32m What\u001b[0m\u001b[32m is\u001b[0m\u001b[32m the\u001b[0m\u001b[32m growth\u001b[0m\u001b[32m projection\u001b[0m\u001b[32m of\u001b[0m\u001b[32m the\u001b[0m\u001b[32m company\u001b[0m\u001b[32m?\n",
      "\n",
      "\u001b[0m\u001b[32m**\u001b[0m\u001b[32mAnswer\u001b[0m\u001b[32m:\u001b[0m\u001b[32m**\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m The\u001b[0m\u001b[32m company\u001b[0m\u001b[32m plans\u001b[0m\u001b[32m to\u001b[0m\u001b[32m grow\u001b[0m\u001b[32m production\u001b[0m\u001b[32m in\u001b[0m\u001b[32m alignment\u001b[0m\u001b[32m with\u001b[0m\u001b[32m a\u001b[0m\u001b[32m \u001b[0m\u001b[32m50\u001b[0m\u001b[32m%\u001b[0m\u001b[32m C\u001b[0m\u001b[32mAGR\u001b[0m\u001b[32m target\u001b[0m\u001b[32m.\n",
      "\u001b[0m\u001b[32m-\u001b[0m\u001b[32m For\u001b[0m\u001b[32m \u001b[0m\u001b[32m202\u001b[0m\u001b[32m3\u001b[0m\u001b[32m,\u001b[0m\u001b[32m they\u001b[0m\u001b[32m expect\u001b[0m\u001b[32m to\u001b[0m\u001b[32m remain\u001b[0m\u001b[32m ahead\u001b[0m\u001b[32m of\u001b[0m\u001b[32m the\u001b[0m\u001b[32m long\u001b[0m\u001b[32m-term\u001b[0m\u001b[32m \u001b[0m\u001b[32m50\u001b[0m\u001b[32m%\u001b[0m\u001b[32m C\u001b[0m\u001b[32mAGR\u001b[0m\u001b[32m with\u001b[0m\u001b[32m around\u001b[0m\u001b[32m \u001b[0m\u001b[32m1\u001b[0m\u001b[32m.\u001b[0m\u001b[32m8\u001b[0m\u001b[32m million\u001b[0m\u001b[32m cars\u001b[0m\u001b[32m.\n",
      "\u001b[0m\u001b[32m  \n",
      "\u001b[0m\u001b[32m*\u001b[0m\u001b[32mSource\u001b[0m\u001b[32m:\u001b[0m\u001b[32m I\u001b[0m\u001b[32mvery\u001b[0m\u001b[32m Growth\u001b[0m\u001b[32m Rate\u001b[0m\u001b[32m document\u001b[0m\u001b[32m*\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Replace 'file_name.csv' with the path of your actual CSV file\n",
    "# csv_file = 'processed_tesla_embeddings.csv'\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv(csv_file)\n",
    "display(df)\n",
    "\n",
    "\n",
    "# Initialize the AIAssistant\n",
    "ai_summarizer = aiSummarizer()\n",
    "\n",
    "        \n",
    "def get_answer_stream(user_query, combined_text):\n",
    "    for chunk in openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\", #gpt-3.5-turbo\n",
    "        messages = [\n",
    "          \n",
    "          {\"role\": \"user\", \"content\": f\"\"\"Follow the instruction carefully.\n",
    "            This is a program let the user ask questions about their file. File: {combined_text}\\n User question: {user_query}? \\\n",
    "              Only answer what asked, do not change the question. \n",
    "              Keep answer short and precise, cite the source. \n",
    "              Show both question and answer in Markdown format.\n",
    "              Use bullet points for answer: \\\n",
    "                \n",
    "                \"\"\"\n",
    "                },\n",
    "        ],\n",
    "        stream=True,\n",
    "    ):\n",
    "        content = chunk[\"choices\"][0].get(\"delta\", {}).get(\"content\")\n",
    "        if content is not None:\n",
    "            print(colored(content, 'green'), end='')\n",
    "        \n",
    "        \n",
    "while True:\n",
    "    # Prompt user for search query\n",
    "    user_query = input(\"Search earnings for a sentence (Press 'esc' to quit): \")\n",
    "    \n",
    "    # If user leaves input empty or hits \"esc\" key, break out of the loop\n",
    "    if not user_query or user_query == '\\x1b':\n",
    "        break\n",
    "    \n",
    "    user_query_vector = get_embedding(user_query, engine=\"text-embedding-ada-002\")\n",
    "\n",
    "    # Do similarity search\n",
    "    df[\"similarities\"] = df['embedding'].apply(lambda x: cosine_similarity(x, user_query_vector))\n",
    "    df = df.sort_values(\"similarities\", ascending=False)\n",
    "\n",
    "    # Display search results\n",
    "    # display(df.head())\n",
    "\n",
    "    # Combine the text from the 3 best matches\n",
    "    top_blocks = df.head(4)['text'].tolist()\n",
    "    combined_text = ' '.join(top_blocks)\n",
    "    length = len(combined_text)  \n",
    "    # print(f\"Length of original text: {length}\")\n",
    "    # prettyPrint(combined_text)\n",
    "\n",
    "    # If length of the combined text is greater than 3500, then summarize it\n",
    "    if length > 3500:\n",
    "        print(\"Summarizing combined text...\")\n",
    "\n",
    "        # Summarize the input text\n",
    "        summary = ai_summarizer.summarize_text(combined_text)\n",
    "    else:\n",
    "        summary = combined_text\n",
    "    # #Get answer streaming:\n",
    "    # get_answer_stream(user_query, combined_text)\n",
    "    \n",
    "    # Get the answer markdown \n",
    "    # answer = get_answer(user_query, summary)\n",
    "\n",
    "    # Display the answer in Markdown format\n",
    "    # display(Markdown(answer))\n",
    "    get_answer_stream(user_query, summary)\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
